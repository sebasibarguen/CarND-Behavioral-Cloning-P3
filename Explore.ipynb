{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import argparse\n",
    "import json\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Lambda, ELU\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_commaai_model(img_shape):\n",
    "    \"\"\"\n",
    "    Creates the comma.ai model, and returns a reference to the model\n",
    "    The comma.ai model's original source code is available at:\n",
    "    https://github.com/commaai/research/blob/master/train_steering_model.py\n",
    "    \"\"\"\n",
    "    row, col, ch = img_shape  # camera format\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Lambda(lambda x: x/127.5 - 1.,\n",
    "        input_shape=(row, col, ch),\n",
    "        output_shape=(row, col, ch)))\n",
    "    model.add(Convolution2D(16, 8, 8, subsample=(4, 4), border_mode='same'))\n",
    "    model.add(ELU())\n",
    "    model.add(Convolution2D(32, 5, 5, subsample=(2, 2), border_mode='same'))\n",
    "    model.add(ELU())\n",
    "    model.add(Convolution2D(64, 5, 5, subsample=(2, 2), border_mode='same'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(.2))\n",
    "    model.add(ELU())\n",
    "    model.add(Dense(512))\n",
    "    model.add(Dropout(.5))\n",
    "    model.add(ELU())\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   0   1   2    3    4    5  \\\n",
      "0  ./sim_data/IMG/center_2017_02_06_19_43_06_277.jpg NaN NaN  0.0  0.0  0.0   \n",
      "1  ./sim_data/IMG/center_2017_02_06_19_43_06_382.jpg NaN NaN  0.0  0.0  0.0   \n",
      "2  ./sim_data/IMG/center_2017_02_06_19_43_06_498.jpg NaN NaN  0.0  0.0  0.0   \n",
      "3  ./sim_data/IMG/center_2017_02_06_19_43_06_614.jpg NaN NaN  0.0  0.0  0.0   \n",
      "4  ./sim_data/IMG/center_2017_02_06_19_43_06_719.jpg NaN NaN  0.0  0.0  0.0   \n",
      "\n",
      "          6  \n",
      "0  0.000007  \n",
      "1  0.000011  \n",
      "2  0.000009  \n",
      "3  0.000013  \n",
      "4  0.000007  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.misc import imread\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "log_file = 'sim_data/driving_log.csv'\n",
    "df = pd.read_csv(log_file, sep=',',header=None)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "img_shape = imread(df[0][0]).shape\n",
    "features = np.zeros([len(df), img_shape[0], img_shape[1], img_shape[2]])\n",
    "labels = np.zeros([len(df), 1])\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    features[i] = imread(row[0])\n",
    "    labels[i] = row[3]\n",
    "\n",
    "# data = {\n",
    "#     'features': features,\n",
    "#     'labels': labels\n",
    "# }\n",
    "\n",
    "# with open('train.p', 'wr') as f:\n",
    "#     pickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(features, labels, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160, 320, 3)\n",
      "Epoch 1/10\n",
      "1901/1901 [==============================] - 4s - loss: 0.1955 - acc: 0.0195     \n",
      "Epoch 2/10\n",
      "1901/1901 [==============================] - 4s - loss: 0.0581 - acc: 0.0216     \n",
      "Epoch 3/10\n",
      "1901/1901 [==============================] - 4s - loss: 0.0369 - acc: 0.0268     \n",
      "Epoch 4/10\n",
      "1901/1901 [==============================] - 4s - loss: 0.0321 - acc: 0.0289     \n",
      "Epoch 5/10\n",
      "1901/1901 [==============================] - 4s - loss: 0.0269 - acc: 0.0300     \n",
      "Epoch 6/10\n",
      "1901/1901 [==============================] - 4s - loss: 0.0291 - acc: 0.0289     \n",
      "Epoch 7/10\n",
      "1901/1901 [==============================] - 4s - loss: 0.0281 - acc: 0.0305     \n",
      "Epoch 8/10\n",
      "1901/1901 [==============================] - 4s - loss: 0.0282 - acc: 0.0305     \n",
      "Epoch 9/10\n",
      "1901/1901 [==============================] - 4s - loss: 0.0250 - acc: 0.0321     \n",
      "Epoch 10/10\n",
      "1901/1901 [==============================] - 4s - loss: 0.0225 - acc: 0.0305     \n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape[1:])\n",
    "\n",
    "model = get_commaai_model(X_train.shape[1:])\n",
    "\n",
    "history = model.fit(X_train, y_train)\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': [0.1954845493793613, 0.058064673801414717, 0.03693534135975253, 0.032086640935408826, 0.026911446915793457, 0.02914836869498167, 0.028137461203437051, 0.028235089660929354, 0.025016887357428099, 0.022514220339141744], 'acc': [0.019463440294581798, 0.021567596041297109, 0.026827985270910047, 0.02893214099802888, 0.029984218832193581, 0.028932140978432403, 0.030510257778670648, 0.030510257759074171, 0.032088374559312419, 0.030510257759074171]}\n"
     ]
    }
   ],
   "source": [
    "print(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "815/815 [==============================] - 1s     \n",
      "[0.062781790794770406, 0.019631901840490799]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_val, y_val)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:carnd-term1]",
   "language": "python",
   "name": "conda-env-carnd-term1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
